---
title: "Data Salaries"
output:
  html_document:
    toc: true
    toc_depth: 2
---

# Problem

Salary is a crucial component for employees, job hunters, and organizations, especially in the field of data science, which is in constant growth, understanding the factors that affect data science job salaries could be a way to help individuals and businesses keep track of the market trends, making informed choices. It also allows organizations to set up fair and competitive salary ranges, as well as support discussions while hiring employees for a particular job.

# Data Mining task

For our project, we intend to employ two data mining techniques which are classification and clustering. These methods will assist us in analyzing data to develop a predictive model for estimating the salaries. Our goal is to explore the influence of diverse job and employee characteristics on salary amounts through these analytical approaches.

For classification, we will train our model to be able to predict the class label(salary in usd) for science job, and the prediction is made on the rest of the attributes like work_year, employment_type, joUSDb_title, salary, remote_ratio, etc.

For clustering, our model will generate a series of clusters for Science job salaries with comparable characteristics. These clusters will be instrumental in predicting outcomes for new Science job salaries.

# Data

## Goal of collecting this Dataset

Predicting Data Science job salaries using classification and clustering.

## The source of the dataset

Link to the source Dataset

<https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023?resource=download>

## Information about the Dataset

Number of Attributes: 11

Type of Attributes: nominal, ordinal, numeric

Number of objects: 3755

Class name: salary in usd

+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| Attributes names   | Description                                                                                 | Data type        | Possible values                                                                                                                  |
+====================+=============================================================================================+==================+==================================================================================================================================+
| work_year          | The year the salary was paid                                                                | numirec          | Range between 2020-2023                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| experience_level   | The experience level in the job during the year                                             | ordinal          | (SE:"Senior",MI:"Mid level",EN:"Entry level,EX:"Executive level")                                                                |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| employment_type    | The type of employment for the role                                                         | nominal          | (FT:"Full time",PT:"Part time",CT:"Contractual",FL:"Freelancer")                                                                 |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| job_title          | The role worked in during the year                                                          | nominal          | (Data Engineer, Data Scientist,Data Analyst, Machine Learning Engineer, Analytics Engineer...)It has 93 categories               |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salary             | The total gross salary amount paid                                                          | numeric interval | Range Between [6000 - 30.4m]                                                                                                     |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salary_currency    | The currency of the salary paid as an ISO 4217 currency code                                | nominal          | USD,EUR,GBP,INR,CAD...)                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salaryinusd        | The salary in USD                                                                           | numeric interval | Between[5132-450k]                                                                                                               |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| employee_residence | Employee's primary country of residence in during the work year as an ISO 3166 country code | nominal          | (US,GB,CA,ES,IN...)It has 78 categories                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| remote_ratio       | The overall amount of work done remotely                                                    | numeric Ratio    | (0, 50, 100)                                                                                                                     |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| company_location   | The country of the employer's main office or contracting branch                             | nominal          | (AE, AL, AM, AR. AS, AT, AU, BA BE, BO, BR, BS, CA, CF, CH, CL, CN, CO, CR, CZ, DE, DK, DZ, EE, EG,ES......)It has 72 categories |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| company_size       | The median number of people that worked for the company during the year                     | ordinal          | (S,M,L)                                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+

## library used

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(magrittr)
```

## uploading the data and raw samples

raw data samples

```{r}
ds_salaries= read.csv(url("https://raw.githubusercontent.com/DeemAlshaye/Miningproject/main/dataset/ds_salaries.csv"), header=TRUE)
head(ds_salaries)
tail(ds_salaries)
```

```{r}
dim(ds_salaries)
```

## summarization and plotting

## summary the data

we used summary function to show each numeric value min, median, max, Q1 and Q3 which Q1 represents first quartile and Q3 represents third quartile

```{r}
summary(ds_salaries)
```

## statical mesurment

Statistical measurements allows to explore our data in a quantitative manner,it helps to understand its distribution, variability, and key characteristics.

```{r}
mean(ds_salaries$salary)
median(ds_salaries$salary)
quantile(ds_salaries$salary)
```

we see that the mean is close to the median,and quantiles has high changes

```{r}
mean(ds_salaries$salary_in_usd)
median(ds_salaries$salary_in_usd)
quantile(ds_salaries$salary_in_usd)
```

we see that the mean is close to the median,and quantiles are close to one another.

```{r}
mean(ds_salaries$remote_ratio)
median(ds_salaries$remote_ratio)
quantile(ds_salaries$remote_ratio)
```

with only 3 valus for remote ratio we see a big diifrence between mean and median with the median being 0 which means most work done was not online and the quantile with the values 0 and 100 meaning there is really low number of work done half online half offline.

```{r}
mean(ds_salaries$work_year)
median(ds_salaries$work_year)
quantile(ds_salaries$work_year)
```

we see that the median is 2022 which means that most people work year is 2022, and the quantile shows that the number of employee with a work year of 2020 are the least.

```{r}
var(ds_salaries$salary)
var(ds_salaries$salary_in_usd)
var(ds_salaries$remote_ratio)
var(ds_salaries$work_year)
```

we see that the var of salary is really high meaning higher risk var of salary in usd is also really high meaning higher risk the var of remote ratio is high but not quit high as salary and salary in usd meaning high risk work year var is low meaning lower risk

## changing the salary and salary in usd to be in 1000s

```{r}
ds_salaries$salary_1000s <- ds_salaries$salary /1000
head(ds_salaries$salary_1000s)

ds_salaries$salaryusd_1000s <- ds_salaries$salary_in_usd /1000
head(ds_salaries$salaryusd_1000s)
```

## graphs

we compared some variables with each other to find how they are distributed

#### boxplot:

```{r}
boxplot(ds_salaries$salary_1000s,ylim=c(0,1000),xlab="Salary",ylab="Salary in 1000s" ,main="boxplot of salary in 1000s")
```

Box plot represents salaries of employees, it displays the five number summary of the salary min, median, max, Q1 and Q3, it shows that the salary has a lot of outliers that are need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$salaryusd_1000s,ylim=c(0,1000),xlab="Salary in USD",ylab="Salary in usd 1000s" ,main="boxplot of salary in usd in 1000s")
```

Box plot represents salary in (usd), it displays the five number summary of the salary in USD min, median, max, Q1 and Q3, it shows that the salary in USD has a lot of outliers thats need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$work_year,xlab="Work year",ylab="Frequency"  ,main="boxplot of Work year")
```

Box plot represents work year at (2020,2021,2022,2023), the work year box plot shows that there is a one outlier of 2020 year, that will be smoothed later to have more accurate data

### histogram

```{r}
hist(ds_salaries$salary_1000s,ylim=c(0,100),ylab="Frequency",xlab="salary in 1000s",main = "Salary Frequency")

```

The histogram represents the frequency of salaries for each employee, it shows that most employees has small amount of salary

### bar plot

```{r}


ds_salaries$remote_ratio %>% table() %>% barplot(xlab="remote ratio", main="barplot of remote ratio")


ds_salaries$work_year %>% table() %>% barplot(xlab="work year", ylab="number of employees", main="barplot of work year")


  library(ggplot2)
library(tidyverse)
top_5_job_salaries<-ds_salaries%>%
  group_by(job_title)%>%
  summarise(Avg_Sal=mean(salary_1000s))%>%
  arrange(desc(Avg_Sal))%>%
  head()
top_5_job_salaries

```

We have tow bar plot one is for remote ratio and the other one for work year

First, the bar plot of 'remote ratio' represent the total of remote ratio for each employee, it show that most employees work on site then the employees who work online, the employees who work on both (online and onsite) have the smaller frequency

Second, the bar plot of 'work year' represent the work year and number of employee in each year, it show that 2020 year has the lowest number of employees and 2023 year has the highest number of employees , we note that the number of employees increases annually

### Scatter plot

```{r}
  with(ds_salaries,plot(ds_salaries$salary_1000s,ds_salaries$salaryusd_1000s,xlab="salary in 1000s",ylab = "salary in usd 1000s",main="Scatter plot with salary and salary in USD") )
```

The scatter plot represents the correlation between salary and salary in usd, we notice that most of the salary and salary in usd are redundant data and the two attributes are strongly correlated

### pie chart

```{r}
library(dplyr)
ds_salaries2 <- ds_salaries %>% sample_n(50)

tab <- ds_salaries2$company_size%>% table()
precentages <- tab %>% prop.table() %>% round(3)*100
txt <- paste0(names(tab),'\n',precentages,'%')
pie(tab,labels=txt)

```

The pie chart represents the percentages for company size by taking a sample of company, it shows that 1(Large) has the middle frequency and represent 18%, 2(Medium) has the highest frequency and represent 80%, and 3(Small) has the lowest frequency and represent 2% of Visualization

```{r}
ggplot(top_5_job_salaries, aes(x=job_title, y=Avg_Sal)) +
  geom_col() +
  labs(title="Top 5 Job Title Salaries", x="Job Title", y="Salary in 1000s") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

the bar plot of 'Top 5 job Title Salaries' represent the job title and the salary for each job, it shows that Head of Machine Learning has the highest salary, Principal Data Architect has the middle salary, and BI Data Analyst has the lowest amount of salary

```{r}
ggplot(ds_salaries, aes(x=experience_level, y=salaryusd_1000s)) +
  geom_boxplot(fill="pink") +
  labs(title="Distribution of Salary by Experience Level", x="Experience Level", y="Salary in 1000s") +
  theme_minimal()
```

the box plot represent the percentages for experience level by taken sample of employees, it shows that salary are different for each experience level, Also employees with the same experience level can have significantly higher or lower salary than there category which can be observed from the box plot as outliers

## Average Salaries in each Year

```{r}
  library(dplyr)

yearly_salary_avg<-ds_salaries%>%
  group_by(work_year)%>%
  summarise(avg_salary=mean(salary_in_usd))
yearly_salary_avg
    
```

This table show the average salary increases annually for each year

# Data preprocessing

Data preprocessing is an essential step in the data analysis process. It involves cleaning and transforming raw data into a format suitable for analysis

## Data cleaning

### categorizing job title

Categorize job title column

```{r}
library(tidyverse)
categorize_job_title <- function(title) {
  title <- tolower(title)
  if (grepl("data scientist|research scientist|researcher|scientist|science", title)) {
    return("Data Scientist")
  } else if (grepl("data engineer|etl|machine learning software engineer|ai|data architect|engineer|data modeler|machine learning engineer|devops", title)) {
    return("Data Engineer")
  } else if (grepl("data analyst|bi|analyst|head of data|data lead|data strategist|data analytics|specialist|data manager", title)) {
    return("Data Analyst")
  } else {
    return("Other")
  }
}
ds_salaries <- ds_salaries %>% 
  mutate(job_title = sapply(job_title, categorize_job_title))
head(ds_salaries)
```

The original dataset had 93 different job title categories, which could make analysis and grouping challenging. By categorizing the job titles into broader categories such as "Data Scientist," "Data Engineer," "Data Analyst," and "Other," it becomes easier to analyze and compare salaries based on job roles. The categorization is performed based on keyword matching using regular expressions.

### Categorizing company location:

```{r}


# Define the country categories
asia <- c("AE", "CN", "HK", "ID", "IN", "JP", "KR", "MY", "PH", "SG", "TH", "TW", "VN")
europe <- c("AL", "AM", "AT", "BA", "BE", "BG", "BY", "CH", "CZ", "DE", "DK", "EE", "ES", "FI", "FR", "GB", "GE", "GR", "HR", "HU", "IE", "IL", "IT", "LT", "LU", "LV", "MD", "MK", "MT", "NL", "NO", "PL", "PT", "RO", "RS", "RU", "SE", "SI", "SK", "TR", "UA", 'ES')

north_america <- c("CA", "US")
south_america <- c("AR", "BO", "BR", "BS", "CL", "CO", "CR", "DO", "EC", "GT", "HN", "JM", "MX", "NI", "PA", "PE", "PY", "SV", "UY", "VE")
oceania <- c("AS", "AU", "FJ", "GU", "KI", "MH", "MP", "NC", "NF", "NZ", "PG", "PW", "SB", "TO", "TV", "VU", "WS")
africa <- c("BF", "BI", "BJ", "BW", "CD", "CG", "CI", "CM", "CV", "DJ", "DZ", "EG", "ET", "GA", "GH", "GM", "GN", "GQ", "KE", "LR", "LS", "LY", "MA", "MG", "ML", "MR", "MU", "MW", "MZ", "NA", "NE", "NG", "RE", "RW", "SC", "SD", "SH", "SL", "SN", "SO", "SS", "ST", "SZ", "TD", "TG", "TN", "TZ", "UG", "ZA", "ZM", "ZW")

# Function to categorize the company locations
categorize_location <- function(location) {
  if (location %in% asia) {
    return("Asia")
  } else if (location %in% europe) {
    return("Europe")
  } else if (location %in% north_america) {
    return("North America")
  } else if (location %in% south_america) {
    return("South America")
  } else if (location %in% oceania) {
    return("Oceania")
  } else if (location %in% africa) {
    return("Africa")
  } else {
    return("Other")
  }
}

# Apply the categorization to the company location column
ds_salaries$company_location <- sapply(ds_salaries$company_location,categorize_location)

# Print the updated dataset with categories
tail(ds_salaries)
```

The dataset had 72 different company location categories. To facilitate analysis based on geographical regions, the locations are categorized into broader regions such as Asia, Europe, North America, South America, Oceania, Africa, and Other. The categorization is done based on predefined lists of countries corresponding to each region.

### finding missing data

Checking for missing values is essential to identify any gaps or inconsistencies in the dataset. By using the is.na() function, we determined that there were no missing values in the dataset. This ensures that our analysis is based on complete data without any missing information.

```{r}
sum(is.na(ds_salaries))
```

we did not have any missing values.

### finding outliers:

Outliers can significantly impact statistical analysis and modeling results. By using boxplots and the boxplot.stats() function, we identified outliers in the numeric attributes: salary, salary_in_usd, remote_ratio, and work_year. Outliers may indicate data entry errors or anomalies that need to be investigated further.

```{r}
boxplot.stats(ds_salaries$salary)$out
boxplot.stats(ds_salaries$salary_in_usd)$out              
boxplot.stats(ds_salaries$remote_ratio)$out
boxplot.stats(ds_salaries$work_year)$out
```

We did detect the outliers in our numeric attributes

### Sum outliers:

The sum() function was used to calculate the total number of outliers in each numeric attribute. This provides an overview of the extent of outliers present in the dataset and helps understand their impact on the analysis.

```{r}
sum(boxplot.stats(ds_salaries$salary)$out)

sum(boxplot.stats(ds_salaries$salary_in_usd)$out)

sum(boxplot.stats(ds_salaries$remote_ratio)$out)

sum(boxplot.stats(ds_salaries$work_year)$out)
```

### removing the outliers:

Outliers can introduce bias and skewness in the data, leading to inaccurate analysis and modeling results. In this case, the outliers were removed using the interquartile range (IQR) method. The filter() function from the dplyr package was used to remove the rows containing outliers in the specified numeric attributes. By removing outliers, we ensure that our data is more representative of the majority of values and reduces the potential for misleading conclusions.

```{r}


library(dplyr)

# Remove outliers for each variable
ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )

ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )
```

We did this to make sure our data is more accurate and representative of the majority of the values.The justification for these techniques is to enhance the quality of the data and improve the validity of the analysis. By identifying and handling missing values, outliers, and anomalies, we ensure that our data is accurate, reliable, and suitable for analysis.

## Data transformation

### Normalization

Normalizing the data helps in improving the performance of machine learning models by scaling the data between 0 and 1. In this case, the normalize() function was applied to the salary and salary_in_usd attributes. Normalization ensures that these variables are on a similar scale, preventing one from dominating the other during analysis or modeling.

```{r}
normalize <- function(x) {return((x-min(x))/(max(x)-min(x)))}
ds_salaries$salary<-normalize(ds_salaries$salary)
ds_salaries$salary_in_usd<-normalize(ds_salaries$salary_in_usd)

num1_cols=ds_salaries[, c(5,7 )] 
head(num1_cols)
```

### Discretization

Discretization is used to transform continuous data into categorical values. In this case, the cut() function was utilized to discretize the salary_in_usd attribute into three categories: "low," "mid," and "high." Discretization simplifies the analysis and interpretation of the data.

```{r}


breaks <- quantile(ds_salaries$salary_in_usd, 
                   probs = c(0, 1/3, 2/3,1), 
                   na.rm = TRUE)

ds_salaries$salary_in_usd_disc <- cut(ds_salaries$salary_in_usd, 
                             breaks = breaks, 
                             include.lowest = TRUE, 
                             labels=c("low", "mid", "high"))
head(ds_salaries$salary_in_usd_disc)
                               
```

### Encoding

Encoding involves converting categorical or ordinal variables into a numerical representation that can be used for analysis and modeling. In this case, several attributes were encoded using the factor() function. The company_size and experience_level attributes were converted into ordinal variables by assigning numerical labels. The work_year and remote_ratio attributes were converted into categorical variables using specific levels and labels. The remaining attributes were also encoded as factors to ensure consistency in their representation.This transformation is necessary because many machine learning algorithms and statistical techniques require numerical inputs

```{r}
ds_salaries$company_size = factor(ds_salaries$company_size,levels = c("S","M","L"),labels = c(1,2,3))
ds_salaries$experience_level = factor(ds_salaries$experience_level,levels = c("EN","MI","SE","EX"),labels = c(1,2,3,4))

# Convert work_year to a categorical variable
ds_salaries$work_year <- factor(ds_salaries$work_year, levels = c(2021, 2022, 2023), labels = c("2021", "2022", "2023"))

# Convert remote_ratio to a categorical variable
ds_salaries$remote_ratio <- factor(ds_salaries$remote_ratio, levels = c(100, 50, 0), labels = c("100%", "50%", "0%"))

ds_salaries$job_title  <- factor(ds_salaries$job_title)
ds_salaries$employment_type  <- factor(ds_salaries$employment_type)
ds_salaries$employee_residence  <- factor(ds_salaries$employee_residence)
ds_salaries$company_location  <- factor(ds_salaries$company_location)
ds_salaries$salary_currency  <- factor(ds_salaries$salary_currency)


num_cols=ds_salaries[, c(2,11 )]
head(num_cols)
```

we encoded our ordinal and nominal variables using factor

## Removing irrelevant and duplicate attributes from the dataset

our data set has 2 salary coulombs salary, and salary in usd, for this, we will measure the correlation between them

```{r}

cor(ds_salaries$salary,ds_salaries$salary_in_usd)
```

we see that salary and salary_in_usd are highly correlated, to avoid redundancy, we will only take the salary in USD.

we decided to remove employee resident due to its being irrelevant to our data sense the employee resident has nothing to do with his salary.

we also decided to remove salary currency sense we only took salary in USD.

```{r}
library(tidyverse)
ds_salaries <- ds_salaries %>%
  select(salary_in_usd_disc,work_year,experience_level,employment_type,job_title,company_location,company_size,remote_ratio)
  head(ds_salaries)
```


for our  small dataset with a few attributes, feature selection may not be as critical. With fewer attributes, the computational cost of training a model is generally lower, and the risk of overfitting may be reduced. Additionally, removing features from small datasets may lead to a loss of information that could potentially be valuable for modeling, so we decided not to preform it.

## snapshot of the original dataset

```{r}
original_dataset= read.csv(url("https://raw.githubusercontent.com/DeemAlshaye/Miningproject/main/dataset/ds_salaries.csv"), header=TRUE)
head(original_dataset)
tail(original_dataset)
```

## snapshot of the preprossesd dataset

```{r}
preprossesd_dataset= read.csv(url("https://raw.githubusercontent.com/DeemAlshaye/Miningproject/main/dataset/preprossesData.csv"), header=TRUE)
head(preprossesd_dataset)
tail(preprossesd_dataset)
```

# Evaluation and Comparison

# Data Mining Technique: Classification

The classification process involves dividing our dataset into training and testing subsets to build and evaluate machine learning models.that will predict the class lable(salary in usd) which has three classes:low,mid,and high,the prediction is made on the rest attributes, we will explore three different split ratios: 1- Training(80%) and Testing(20%) 2- Training(70%) and Testing(30%) 3- Training(90%) and Testing(10%), along with different decision tree algorithms that utilize the Gini index, Gain ratio, and Information gain as selection measures.

The r packages used in the classification

• caret: This package is used for data splitting and other data manipulation tasks. • rpart: This package is used for building decision trees using the Gini index as the splitting criterion. • rpart.plot: This package is used for visualizing the resulting decision tree. • C50: This package is used for building decision trees using different splitting measures such as gain ratio. • printr: This package is used to print the decision tree model in a visually appealing format.

## checking if the data is balanced

```{r}
barplot(prop.table(table(ds_salaries$salary_in_usd_disc)),
        col = rainbow(2),
        ylim = c(0, 0.7),
        main = "Class Distribution")
```

```{r}
class_percentages <- prop.table(table(ds_salaries$salary_in_usd_disc)) * 100
print(class_percentages)
```

as shown in the bar plot above, and the class percentages, our class label is balanced, so we can split our data randomly without further steps.

## 1-Split the datasets into two subsets: Training(80%) and Testing(20%):

We chose this split because it helps Allocating 80% of the data for training provides a substantial amount of data for the model to learn from. With more training data, the model has a better chance of capturing the underlying patterns and relationships within the data, leading to improved performance. Setting aside 20% of the data for testing ensures that there is a sizable portion of unseen data available for evaluating the model's performance. Having a sufficient amount of testing data helps in obtaining reliable estimates of the model's accuracy and generalization ability.

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train <- create_train_test(ds_salaries, 0.8, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.8, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

The train dataset has 2837 rows while the test dataset has 710 rows.

we use the function prop.table() combined with table() to verify if the randomization process is correct.

```{r}
prop.table(table(data_train$salary_in_usd_disc))
```

```{r}
prop.table(table(data_test$salary_in_usd_disc))
```

### A-Decision Tree Using gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Engineer," "Data Scientist," or "Other, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a high probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

rpart() function uses the Gini impurity measure to split the note.

```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

The overall accuracy of the model is 55.77%. This means that the model correctly predicts the salary category for approximately 55.77% of the instances in the unseen dataset.

Sensitivity: - For the low salary category, the sensitivity is 70.15%, indicating that the model correctly identifies 70.15% of instances with low salaries. - For the mid salary category, the sensitivity is only 17.13%, suggesting that the model struggles to identify instances with mid-range salaries. - For the high salary category, the sensitivity is 77.51%, indicating good performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 76.62%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 86.84%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 70.61%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

Overall, the Gini Index shows moderate performance in predicting salary categories. It performs relatively well in identifying instances with high salaries, but struggles with instances in the mid salary range. The model achieves better accuracy for instances that do not belong to the low salary category compared to the mid and high salary categories.

precision: indicating the proportion of instances correctly predicted as a specific class compared to all instances predicted as that class. The positive predictive values for the "low," "mid," and "high" classes are 0.7170, 0.36275, and 0.4517, respectively.

### B-Decision Tree Using gain ratio

```{r}
library(C50)
library(printr)
library(caret)

```

Train decision tree

```{r}
model <- C5.0(salary_in_usd_disc ~., data=data_train)
```

Test

```{r}
results <- predict(model, data_test, type="class")

```

```{r}

plot(model, type="simple")
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 14.3% error.
-   If the company location is in North America, the model considers the employment type. If it's in "CT" or "FL" or "PT",it predicts a low salary with about 11.1% error.
-   If the employment type "FT" and job title is "Data Engineer" or "Data Scientist" or "other" the model looks at the experience level. For example, if it's 1 or 2 the model looks for remote ratio if it was 100%(which means online) or 50%(which means both on site and online), it predicts a low salary. for 0%(on site), it predicts a mid salary.
-   if the experience level was 3 or 4 it takes into account factors such as work year and remote work ratio and experience level to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

Overall Accuracy: The overall accuracy of the model is 53.8%. This means that the model correctly predicts the salary category for approximately 53.8% of the instances in the dataset.

Sensitivity:

-   For the low salary category, the sensitivity is 80.31%, indicating that the model correctly identifies 80.31% of instances with low salaries.
-   For the mid salary category, the sensitivity is only 15.74%, suggesting that the model struggles to identify instances with mid-range salaries.
-   For the high salary category, the sensitivity is 51.48%, indicating a moderate performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 65.19%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 82.79%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 79.85%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

the precision values for the "low," "mid," and "high" classes are 0.7222, 0.5, and 0.5143, respectively.

Overall, the model shows moderate performance in predicting salary categories. It performs relatively well in identifying instances with low and high salaries but struggles with instances in the mid salary range. The model achieves better accuracy for instances that do not belong to the mid and high salary categories compared to the low salary category.

### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  
 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work.experience level, and company size, Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

### Interpreting the results of Confusion Matrix and Statistics for information gain

-   The overall accuracy of the model is 53.38%. This means that the model correctly predicts the salary category for approximately 53.38% of the instances in the dataset.

Sensitivity:

-   For the low salary category, the sensitivity is 76.92%, indicating that the model correctly identifies 76.92% of instances with low salaries.
-   For the mid salary category, the sensitivity is 19.44%, suggesting that the model struggles to identify instances with mid-range salaries.
-   For the high salary category, the sensitivity is 51.48%, indicating a moderate performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 72.99%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 78.95%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 77.26%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

### Comparing and Interpreting the performance of the model using diffrent selection measures

The performance of the model was evaluated using three different selection measures: Gini index, Gain ratio, and Information gain.

In terms of accuracy, the Gini index measure achieved the highest accuracy rate of 55.77%, followed by Gain ratio with 53.8%, and Information gain with 53.38%. This indicates that the model's predictions aligned more closely with the actual salary categories when using the Gini index measure.

When considering balanced accuracy, which takes into account the performance across all classes, the Gini index measure outperformed the other two measures in most categories. It achieved a balanced accuracy of 73.39% for the low salary category, 74.06% for the high salary category, and 51.99% for the mid salary category. The Gain ratio and Information gain measures had relatively lower balanced accuracy scores in all categories.

the Gini index measure demonstrated better performance in most cases. It achieved higher sensitivity values for low (70.15%) and high (77.51%) salary categories compared to the other measures. However, it struggled with sensitivity for the mid salary category (17.13%). The Gini index measure also exhibited better specificity for the low (76.62%) and high (70.61%) salary categories. The Gain ratio and Information gain measures showed moderate sensitivity and specificity values across all salary categories.

In summary, the Gini index measure generally outperformed the Gain ratio and Information gain measures in terms of accuracy, balanced accuracy, Kappa, sensitivity, and specificity.

## 2-Split the Dataset into two subsets: Training(70%) and Testing(30%):

We chese this split because the 70% training and 30% testing split offers a significant portion of the dataset for training the model, enabling comprehensive learning and improved performance. The larger training set allows the model to better

```{r}


library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.7, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train70 <- create_train_test(ds_salaries, 0.7, train = TRUE)
data_test70 <- create_train_test(ds_salaries, 0.7, train = FALSE)
dim(data_train70)
```

```{r}
dim(data_test70)
```

The train set has 2482 rows while the test set has 1065 rows.

###A-Decision Tree Using gini index \### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train70, method = 'class')
rpart.plot(fit, extra = 100,type = 4)
```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Engineer," "Data Scientist," or "Other, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a higher probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

rpart() function uses the Gini impurity measure to split the note.

```{r}
predict_unseen70 <-predict(fit, data_test70, type = 'class')
```

```{r}
table_mat70 <- table(data_test70$salary_in_usd_disc,predict_unseen70)
table_mat70
```

```{r}
accuracy_Test70 <- sum(diag(table_mat70)) / sum(table_mat70)
```

```{r}
print(paste('Accuracy for test', accuracy_Test70))
```

```{r}


result70_gini<-table(predict_unseen70, data_test70$salary_in_usd_disc)
co_result70_gini <- confusionMatrix(result70_gini)
print(co_result70_gini)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.For example, the model predicted 299 instances as "low" when the true class was also "low," and it predicted 89 instances as "low" when the true class was "mid," and so on.

The overall accuracy of the model is 54.46%, meaning it correctly classified approximately 54.46% of the instances. The Kappa statistic suggests a fair agreement between the predicted and actual classes.

-   The "low" class has a sensitivity of 67.49%, specificity of 81.67%, and positive predictive value of 72.40%.
-   The "mid" class has a sensitivity of 12.35%, specificity of 88.41%, and positive predictive value of 33.33%.
-   The "high" class has a sensitivity of 84.75%, specificity of 63.35%, and positive predictive value of 45.44%.
-   The negative predictive value is relatively high for all classes, indicating a good ability to correctly identify negative instances.
-   the precision values for the "low," "mid," and "high" classes are 0.7703, 0.3896, and 0.5330, respectively.

### B-Decision Tree Using gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
model70 <- C5.0(salary_in_usd_disc ~., data=data_train70)
```

Make predictions on the test data

```{r}
results70_gain <- predict(object=model70, newdata=data_test70, type="class")

```

```{r}
plot(model70, type="simple")
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 14.6% error.
-   If the company location is in North America, the model considers the job title. If it's in "Data Analyst" or other, the model predicts a low salary with an 51.9% error.
-   If the job title is "Data Engineer" or "Data Scientist", the model looks at the experience level. For example, if it's 3 or 4 the model looks for remote ratio if it was 100%(which means online), it predicts a high salary. for 50%(which means both on site and online), it predicts a mid salary with a 0.0% error, for the 0%(on site), it takes work year into concider.
-   if the experience level was 1 or 2 it takes into account factors such as employment type and remote work ratio and experience level to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

Confusion Matrix and Statistics

```{r}
result70<-table(results70_gain, data_test70$salary_in_usd_disc)
co_result70_gain <- confusionMatrix(result70)
print(co_result70_gain)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

The overall accuracy of the model is 53.24%, indicating that it correctly classified approximately 53.24% of the instances. The 95% confidence interval suggests that the true accuracy of the model falls between 0.5019 and 0.5627.

The performance measures for each class are as follows:

-   For the "low" class:

Sensitivity: 71.11% Specificity: 80.23% Positive Predictive Value: 71.92%

-   For the "mid" class:

Sensitivity: 28.23% Specificity: 76.28% Positive Predictive Value: 35.82%

-   For the "high" class:

Sensitivity: 55.32% Specificity: 74.07% Positive Predictive Value: 43.45%

the model shows varying performance for different classes. The highest accuracy is achieved for the "low" class, while the "mid" class has the lowest accuracy.

### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {



decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train70, method = "class", control = rpart.control(cp = 0))


  rpart.plot(decision_tree, extra = 100, cex = 0.5)
 
  predictions <- predict(decision_tree, newdata = data_test70, type = "class")

  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test70[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
}

classify_dataset(ds_salaries, "salary_in_usd_disc")
```

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America or Other, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work.experience level, and company size, Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

### Interpreting the results of Confusion Matrix and Statistics for information gain

The overall accuracy of the model is 53.8%. This means that the model correctly classified approximately 53.8% of the instances in the dataset.

The 95% confidence interval (CI) for accuracy ranges from 0.5075 to 0.5683. This interval provides a range of values within which we can be 95% confident that the true accuracy of the model lies.

The sensitivity values for each salary category:

For the "low" salary category: The model correctly identifies 59.37% of instances with low salaries. For the "mid" salary category: The model correctly identifies 44.12% of instances with mid-range salaries. For the "high" salary category: The model correctly identifies 56.74% of instances with high salaries.

The specificity values for each non-salary category:

For non-"low" salaries: The model correctly identifies 91.32% of instances with non-low salaries. For non-"mid" salaries: The model correctly identifies 67.03% of instances with non-mid salaries. For non-"high" salaries: The model correctly identifies 74.58% of instances with non-high salaries.

The Precisions, for the "low," "mid," and "high" classes are 0.8595, 0.5747, and 0.5212, respectively.

## 3-Split the datasets into two subsets: Training(90%) and Testing(10%):

we choose this partition sense more training data often leads to better model performance ,By reserving a smaller portion for testing, we reduce the risk of over-fitting to the test set.

### Create train/test function

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.9, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

### using the train/test function

```{r}
data_train <- create_train_test(ds_salaries, 0.9, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.9, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

we see that The train dataset has 3192 rows while the test dataset has 355 rows.

### gini index

Applying Decision trees classification using gini index selection measure

### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

# Plot the tree with a simple text representation
print(fit)

# Generate rules from the decision tree
rules <- rpart.rules(fit)

# Print the rules
print(rules)

```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America or Other, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Analyst" category, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a higher probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

In a simple way, the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

-   For the "low" salary level, the model predicts it correctly 68.78% of the time. The model has a specificity of 75.30%, meaning it correctly identifies non-low salaries 75.30% of the time.
-   For the "mid" salary level, the accuracy is lower, with the model predicting it correctly 23.66% of the time. The specificity for this class is 80.92%.
-   For the "high" salary level, the model predicts it correctly 71.23% of the time. The specificity for this class is 78.72%.

Overall, the accuracy of the model is 57.46%, meaning it predicts the correct salary level about 57.46% of the time. The Kappa value measures the level of agreement between the model's predictions and the actual salary levels, which is 0.32 indicating a fair level of agreement.

### gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
library(caret)

```

### visual representation of the tree for gain ratio

```{r}
library(C50)
library(partykit)
library(rpart.plot)
library(rpart)
library(rpart.plot)

model <- C5.0(salary_in_usd_disc ~., data=data_train)
party_model <- as.party(model)



# Plot the tree using default plotting method
plot(party_model,type="simple")



# Plot the tree with a simple text representation
print(party_model)
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 13.6% error.
-   If the company location is in North America or Other, the model considers the employment type. If it's in CT, FL, or PT, it predicts a low salary with an 8.3% error.
-   If the employment type is FT, the model looks at the job title. For example, if it's a Data Analyst, it predicts a low salary with a 52.5% error. For other job titles like Data Engineer or Data Scientist, it considers the experience level.
-   Based on the experience level, the model predicts either a mid or high salary with specific errors.
-   The model also takes into account factors such as remote work ratio and work year to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

```{r}
results <- predict(model, data_test, type="class")

```

```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

In a simple way, the results show how well the algorithm predicts salary levels based on different factors. The confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high).

Overall, the accuracy of the model is 60.28%, meaning it predicts the correct salary level about 60.28% of the time. The Kappa value indicates a fair level of agreement between the model's predictions and the actual salary levels.

When looking at individual salary levels: - For low salaries, the algorithm correctly predicts them 76.72% of the time. - For mid salaries, the algorithm has a lower accuracy, correctly predicting them 22.58% of the time. - For high salaries, the accuracy of the model is 65.75%.

The specificity measures how well the model predicts non-target classes. - For lowl salaries, the model correctly identifies non-low salaries 72.29% of the time. - For mid salaries, the model identifies non-mid salaries with a specificity of 84.73%. - For high salaries, the specificity is 80.50%.

In general, the model performs better at predicting non-low and non-mid salaries compared to predicting the exact salary level.

### information gain

Applying Decision trees classification using information gain selection measure

### visual representation of the tree for information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  



 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
  

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```

### Interpreting the results of Confusion Matrix and Statistics for information gain

The confusion matrix and statistics provide information about how well the decision tree model performs in classifying salary in usd. Let's break down the important details:

Overall Accuracy: The model's accuracy is 59.44%, meaning it correctly predicts salary in usd about 59.44% of the time.

Kappa: The model's agreement with the actual salary in usd is fair, with a Kappa value of 0.3545.

McNemar's Test: There is a significant difference in the predictions made by the model for different salary in usd.

Sensitivity: The model correctly identifies 70.37% of low salary in usd , 35.48% of mid salary in usd, and 61.64% of high salary in usd.

Specificity: The model correctly identifies 80.72% of non-low salary in usd, 78.63% of non-mid salary in usd, and 80.14% of non-high salary in usd.

Positive Predictive Value: When the model predicts a salary in usd as low, it is right 80.61% of the time. For mid salary in usd, it is right 37.08% of the time, and for high salary in usd, it is right 44.55% of the time.

Negative Predictive Value: When the model predicts a salary in usd as non-low, it is right 70.53% of the time. For non-mid salary in usd, it is right 77.44% of the time, and for non-high salary in usd, it is right 88.98% of the time.

Balanced Accuracy: On average, the model's performance is around 75.55% for low salary in usd, 57.06% for mid salary in usd, and 70.89% for high salary in usd.

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America or Other, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work. Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

## why we chose split ratio instead of k-folds

Our team decided to go with a split ratio for handling our dataset---3547 observations, 8 variables. It's a quicker and computationally efficient option, which suits our early-stage model tweaking. We're also considering class imbalances, and the stratified split looks handy for keeping things balanced. We know it has its quirks, like sensitivity to random splits and potential limitations, but for our goals and where we are with our data, the split ratio feels like a straightforward and practical choice.

## comparing

### gini index

+--------------+------------------------------------+------------------------------------+------------------------------------+
|              | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+==============+====================================+====================================+====================================+
| Accuracy     | 57.46%                             | 55.77%                             | 54.46%                             |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| precision    | -   'low': 76.02%                  | -   'low': 71.70%                  | -   'low': 72.40%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 30.56%                  | -   'mid': 36.28%                  | -   'mid': 33.33%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 46.43%                 | -   'high': 45.17%                 | -   'high': 45.44%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity  | -   'low': 68.78%                  | -   'low': 70.15%                  | -   'low': 67.49%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 23.66%                  | -   'mid': 17.13%                  | -   'mid': 12.35%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 71.23%                 | -   'high': 77.51%                 | -   'high': 84.75%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| specificity  | -   'low': 75.30%                  | -   'low': 76.62%                  | -   'low': 81.67%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 80.92%                  | -   'mid': 86.84%                  | -   'mid': 88.41%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 78.72%                 | -   'high': 70.61%                 | -   'high': 63.35%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+

### gain ratio

+--------------+------------------------------------+------------------------------------+------------------------------------+
|              | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+==============+====================================+====================================+====================================+
| Accuracy     | 60.28%                             | 53.8%                              | 53.24%                             |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| precision    | -   'low': 75.92%                  | -   'low': 66.08%                  | -   'low': 71.92%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 34.43%                  | -   'mid': 28.57%                  | -   'mid': 35.82%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 46.60%                 | -   'high': 44.39%                 | -   'high': 43.45%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity  | -   'low': 76.72%                  | -   'low': 80.31%                  | -   'low': 71.11%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 22.58%                  | -   'mid': 15.74%                  | -   'mid': 28.24%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 65.75%                 | -   'high': 51.48%                 | -   'high': 55.32%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| specificity  | -   'low': 72.29%                  | -   'low': 65.19%                  | -   'low': 80.23%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 84.73%                  | -   'mid': 82.79%                  | -   'mid': 76.28%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 80.50%                 | -   'high': 79.85%                 | -   'high': 74.07%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+

### information gain

+--------------+------------------------------------+------------------------------------+------------------------------------+
|              | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+==============+====================================+====================================+====================================+
| Accuracy     | 59.44%                             | 53.38%                             | 53.38%                             |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| precision    | -   'low': 80.61%                  | -   'low': 76.92%                  | -   'low': 70.62%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 37.08%                  | -   'mid': 19.44%                  | -   'mid': 28.77%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 44.55%                 | -   'high': 51.48%                 | -   'high': 41.43%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity  | -   'low': 70.37%                  | -   'low': 76.92%                  | -   'low': 76.92%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 35.48%                  | -   'mid': 19.44%                  | -   'mid': 19.44%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 61.64%                 | -   'high': 51.48%:                | -   'high': 51.48%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+
| specificity  | -   'low': 80.72%                  | -   'low': 72.99%                  | -   'low': 72.99%                  |
|              |                                    |                                    |                                    |
|              | -   'mid': 78.63%                  | -   'mid': 78.95%                  | -   'mid': 78.95%                  |
|              |                                    |                                    |                                    |
|              | -   'high': 80.14%                 | -   'high': 77.26%                 | -   'high': 77.26%                 |
+--------------+------------------------------------+------------------------------------+------------------------------------+

### What is the best algorithm in each partition

### 90% Training, 10% Testing:

In the 90% training and 10% testing partition, the Gain Ratio algorithm emerged as the preferred choice, achieving an overall accuracy of 60.28%. This accuracy implies that 60.28% of instances were correctly classified across all salary categories.

-   **Sensitivity (True Positive Rate):** For the 'low,' 'mid,' and 'high' salary categories, the algorithm correctly identified 76.72%, 22.58%, and 65.75% of instances, respectively.

-   **Specificity (True Negative Rate):** Specifically, for the 'low,' 'mid,' and 'high' salary categories, the algorithm accurately identified instances that did not belong to these categories at rates of 72.29%, 84.73%, and 80.50%, respectively.

In summary, Gain Ratio provided a well-balanced performance, accurately classifying instances with notable sensitivity and specificity across different salary categories.

### 70% Training, 30% Testing:

In the 70% training and 30% testing partition, the Gini Index stood out with the highest accuracy of 54.46%, denoting that 54.46% of instances were correctly classified.

-   **Sensitivity:** Gini Index demonstrated competitive sensitivity for the 'low,' 'mid,' and 'high' salary categories.

-   **Specificity:** It achieved specificity rates of 72.29%, 84.73%, and 80.50% for the 'low,' 'mid,' and 'high' salary categories, respectively.

This suggests that Gini Index performed slightly better than other measures in accurately classifying instances across different salary categories.

### 80% Training, 20% Testing:

In the 80% training and 20% testing partition, the Gini Index again proved to be the superior choice with an accuracy of 55.77%. This accuracy implies that 55.77% of instances were correctly classified.

-   **Sensitivity:** Gini Index excelled in sensitivity for the 'low' and 'high' salary categories but struggled with sensitivity for the 'mid' category.

-   **Specificity:** It exhibited specificity rates of 76.62%, 70.61%, and 77.51% for the 'low,' 'mid,' and 'high' salary categories, respectively.

In summary, the Gini Index consistently outperformed other measures, showcasing its effectiveness in accurately classifying instances across various salary categories.

### Best Among All:

The 90% training and 10% testing partition with the Gain Ratio attribute selection measure emerged as the best model. The overall accuracy of 60.28% indicates that a significant proportion of instances were correctly classified across different salary categories.

-   **Sensitivity:** The algorithm demonstrated high sensitivity, correctly identifying instances within each salary category.

-   **Specificity:** It exhibited specificity, accurately identifying instances not belonging to each salary category.

These results emphasize the effectiveness of the Gain Ratio algorithm in achieving a balanced classification performance in the specified partition.

# Data Mining Technique: Clustering

We will apply clustering on the data set based on the number of k that represent number of clusters without knowing the class label (unsupervised learning), By applying K-means clustering with different values of K (2,3, and 10), and evaluating the results using various metrics, we can gain insights into the optimal number of clusters and assess the quality of the clustering solution. Visualizing the results aids in understanding the patterns and relationships within the dataset and the algorithm's performance in grouping similar data points together.

the R packages used in clustring are:

-   factoextra: This package is used for visualizing clustering results, such as cluster centers and data points.
-   cluster: This package provides various functions for clustering analysis, including k-means clustering.

```{r}
#sbset of original dataset
ds_salaries_clustering<-ds_salaries
#delete the class label from sebset dataset before running the cluster algorithm
classLable<-(ds_salaries$salary_in_usd_disc)
ds_salaries_clustering <- subset(ds_salaries_clustering,select=-c(salary_in_usd_disc))
```

we made a subset of the original dataset to ds_salaries_clustering to to clustering on the subset dataset

#### change the value of attribute from factor to numeric

```{r}
ds_salaries_clustering$experience_level <- as.numeric(ds_salaries_clustering$experience_level)
ds_salaries_clustering$company_location <- as.numeric(ds_salaries_clustering$company_location)
ds_salaries_clustering$employment_type  <- as.numeric(ds_salaries_clustering$employment_type)
ds_salaries_clustering$company_size <- as.numeric(ds_salaries_clustering$company_size)
ds_salaries_clustering$job_title <- as.numeric(ds_salaries_clustering$job_title)
ds_salaries_clustering$remote_ratio <- as.numeric(ds_salaries_clustering$remote_ratio)
ds_salaries_clustering$work_year <- as.numeric(ds_salaries_clustering$work_year)
```

changing the factors and categorical values to numeric values to facilitate the clustering

**summary the data after transferring to numerical values**

```{r}
summary(ds_salaries_clustering)
str(ds_salaries_clustering)
```

**Scaling the data**

```{r}
# Scaling the data
ds_salaries_clustering=scale(ds_salaries_clustering)
```

## perform K-means clustering

We used the K-means algorithm with varying values of 3 K for clustering, aiming to determine the optimal number of clusters.The kmeans() function from the base R package is used to perform K-means clustering, We computed the average silhouette width for each K, leading to the following conclusions:.

```{r}
perform_kmeans <- function(data, k) {
  set.seed(200) 
  #we choose different number of k (number of clusters) to be the center
  kmeans_result <- kmeans(data, centers = k, nstart = 25)
  return(kmeans_result)
}
```

## different number of clusters:

To visualize the clustering results, the fviz_cluster() function from the factoextra package is used. The quality of the clustering results is evaluated using the silhouette coefficient. The silhouette() function from the cluster package is used to calculate the silhouette scores for each data point based on their assigned clusters. The fviz_silhouette() function from the factoextra package is then used to visualize the silhouette plot.

## k=2

```{r}
library(factoextra)
library(cluster)
set.seed(200)
# Perform k-means clustering
k <- 2
kmeans_result2 <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result2, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result2$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We choose k=2 through visual examination, as it produced the most well-defined clusters without depending on formal validation techniques. The dataset clusters showed clear and easily distinguishable clusters.

-   Cluster 1 has a size of 3166 and an average silhouette width of 0.39. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 385 and an average silhouette width of 0.17. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.

The average silhouette width for k= 2 is equal to 0.37 have the highest value which it highst number of clustering that close to number 1 and we can cluster the data based on it

## k=3

```{r}
set.seed(900)

# Perform k-means clustering
k <- 3
kmeans_result3 <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result3, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result3$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)

```

k=3 is grounded in our observations, specifically guided by the Elbow method. Through this method, we identified k = 3 as the value nearest to the elbow point in the variation plot. This choice proves effective in dividing the dataset into clusters, yielding well-defined and distinct groupings.

-   Cluster 1 has a size of 1411 and an average silhouette width of 0.19. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 379 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
-   Cluster 3 has a size of 1761 and an average silhouette width of 0.36. This indicates that the data points within Cluster 3 are relatively well-matched and separated from other clusters, similar to Cluster 1.

Overall, the results show that Cluster 1 and Cluster 3 have a higher quality in terms of clustering structure and separation, while Cluster 2 may have some overlapping data points or a less distinct clustering pattern.

The average silhouette width for k= 3 is equal to 0.27 have the lowest value for all of the clusters

## k=10

```{r}
set.seed(8203)
# Perform k-means clustering
k <- 10
kmeans_result10 <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result10, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result10$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We initially selected k=10 based on observations using the silhouette coefficient method, aiming for well-separated clusters where objects within the same cluster are close to each other. According to the silhouette coefficient, optimal clustering should yield values between zero and one. However, the actual clustering results did not align with our expectations. The quality of the clusters is considered poor, contradicting the anticipated characteristics. Therefore, k=10 may not be the optimal representation for clustering our dataset.

-   Cluster 1 has a size of 1287 and an average silhouette width of 0.36. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 156 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
-   Cluster 3 has a size of 203 and an average silhouette width of 0.09. This indicates that the data points within Cluster 3 are less well-separated compared to Cluster 1 and 2, with potentially more overlap or ambiguity.
-   Cluster 4 has a size of 41 and an average silhouette width of 0.41. This suggests that the data points within Cluster 4 are relatively well-separated and distinct from other clusters.
-   Cluster 5, 6, 7, 8, 9, and 10 also have their respective sizes and average silhouette widths.

Overall, the results show that different clusters have varying levels of quality in terms of clustering structure and separation. Clusters 1, 4, 9, and 10 seem to have relatively higher quality with well-separated data points, while Clusters 3 and 7 have lower silhouette widths and potentially more

The average silhouette width for k= 10 is equal to 0.32 have the middle value which it between k=2 and k= 3

## Validation

we applied multiple validation methods for our clustering process, and we aim to validate the appropriate number of k for each cluster .

#### Elbow method

The elbow method is used to determine the optimal number of clusters by analyzing the within-cluster sum of squares (WSS) as a function of the number of clusters. The fviz_nbclust() function from the factoextra package is used to visualize the WSS values for different numbers of clusters.

```{r}
library(factoextra) 
fviz_nbclust(ds_salaries_clustering, kmeans, method = "wss") + geom_vline(xintercept= 3, linetype= 2)+
labs(subtitle = "Elbow method")
```

we use the elbow method to determine the right number of clusters for our dataset by using the turning point in the curve to determine the number of clusters that was equal to 3.

#### Silhouette method

The fviz_nbclust() function from the factoextra package is used

```{r}
fviz_nbclust(ds_salaries_clustering, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
```

We use silhouette coefficient (extrinsic method) method to calculate the optimal number of k which k represent the number of clusters and then we observed that the optimal number of clusters to classify our data set that has a highest value and close to number 1 is equal to 10.

#### Total within-cluster sum of square

The total within-cluster sum of squares indicates the sum of squared distances between each point in the dataset. It defines the proximity of points "within the cluster", illustrating the tightness of points within the same cluster.

#### for K=2

```{r}
total_wss <- kmeans_result2$tot.withinss
print(total_wss)
```

When k equal to 2, it shows the highest value indicates that the points in these two clusters are close together, showing a strong clustering pattern. This suggests effective separation between the clusters.

#### for K=3

```{r}
total_wss <- kmeans_result3$tot.withinss
print(total_wss)

```

For k=3, the total_wss falls in the middle between k=2 and k=10, indicating a mid level of clustering. This means a less clear separation among the clusters.

#### for K=10

```{r}
total_wss <- kmeans_result10$tot.withinss
print(total_wss)
```

for k=10, it has the lowest value among the 3 defined k means, that means the points within the same cluster are not close enough to each other.

#### BCubed precision and recall

BCubed Precision and Recall are evaluation metrics used to assess the quality of clustering results, The bcubed_precision_recall() function defines the calculation of these metrics based on the true cluster labels (labels_true) and the predicted cluster assignments (labels_pred).

BCubed Precision and Recall metrics evaluate the Precision and Recall for every object in a clustering on our data set according to the ground truth "class label".

The Precision value is a metric that quantifies the ratio of items from the same category correctly placed in their cluster to the total number of items assigned to that cluster. In other words, it measures the accuracy of the clustering algorithm in correctly grouping items of the same category within their respective clusters. Higher precision values indicate a better ability of the clustering algorithm to avoid false positives and accurately identify items belonging to a specific category within a cluster.

and the Recall value is a metric that gauges the ability of a clustering algorithm to capture and include all items from the same category within their respective clusters. It is calculated as the ratio of the number of items from a specific category correctly assigned to their cluster to the total number of items belonging to that category. In core, Recall measures the algorithm's effectiveness in identifying and including all relevant items of a particular category within their assigned clusters. Higher Recall values signify a better ability to avoid false negatives and ensure comprehensive coverage of items from the same category in the clustering results. here we apply the precision and recall for all k (number of clusters) we choose.

#### for k=2

```{r}

cluster_assignments <- c(kmeans_result2$cluster)
ground_truth_labels <- c(ds_salaries_clustering)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")

```

For k=2, although precision is lower, it has the highest Recall value, suggesting it effectively captures most items from the same category within clusters, even with some overlap. Overall, k=2 is favored as the best number of clusters due to its emphasis on Recall, highlighting its ability to comprehensively include items from the same category in clustering results.

#### for k=3

```{r}

cluster_assignments <- c(kmeans_result3$cluster)
ground_truth_labels <- c(ds_salaries_clustering)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
```

The BCubed precision of 0.1010837 and recall of 0.5055741 for k=3 signify a moderate performance in terms of clustering accuracy. These values indicate that, compared to k=2 where precision is higher but recall might be compromised due to potential overlap, and k=10 where clusters are too close, k=3 achieves a balance.

In essence, for k=3, the clustering model demonstrates a reasonable ability to correctly group items from the same category within clusters while maintaining a certain level of comprehensiveness. The mid-range values suggest that k=3 strikes a trade-off between the precision-oriented approach of k=2 and the recall-oriented approach of k=10. This equilibrium makes k=3 a viable option for clustering in scenarios where achieving a balanced trade-off between precision and recall is desirable. \#### for k=10

```{r}

cluster_assignments <- c(kmeans_result10$cluster)
ground_truth_labels <- c(ds_salaries_clustering)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
```

For k=10, the BCubed precision of 0.1110498 and recall of 0.2913048 these metrics suggest that the precision, or the accuracy of correctly assigning items to their respective clusters, is relatively low. Similarly, the recall, which measures the ability to capture and include all items from the same category within their clusters, is also on the lower side.

The values for k=10 reaffirm the earlier observation that this choice of k leads to overlapping clusters, where points within the same cluster are not closely grouped together. This compromises both precision and recall, making k=10 less effective for capturing distinct and cohesive clusters in the dataset.

In summary, the BCubed precision and recall values for k=10 indicate a suboptimal clustering outcome, reinforcing the notion that this particular choice of k does not align well with the standard expectations and requirements for successful clustering.

+------------------------------------+----------------------+----------------------+----------------------+
|                                    | K=2                  | K=3                  | K=10                 |
+====================================+:=====================+======================+======================+
| Average Silhouette width           | 0.37                 | 0.27                 | 0.32                 |
+------------------------------------+----------------------+----------------------+----------------------+
| total within-cluster sum of square | 21594.76             | 18247.46             | 9646.581             |
+------------------------------------+----------------------+----------------------+----------------------+
| BCubed precision                   | 0.09200684           | 0.1010837            | 0.1110498            |
+------------------------------------+----------------------+----------------------+----------------------+
| BCubed recall                      | 0.8441542            | 0.5055741            | 0.2913048            |
+------------------------------------+----------------------+----------------------+----------------------+
| Visualization                      | In the figures above | In the figures above | In the figures above |
+------------------------------------+----------------------+----------------------+----------------------+

1.  **Average Silhouette Width:** o The silhouette width measures how similar an object is to its own cluster compared to other clusters. A higher value is generally better. In this case, K=2 has the highest silhouette width, suggesting that it might be a better choice based on this metric alone.
2.  **Total Within-Cluster Sum of Square:** o This value represents the compactness of the clusters. A lower value indicates tighter clusters. K=10 has the lowest within-cluster sum of squares, suggesting better cluster compactness. However, this alone doesn't make it the best choice; it depends on the balance with other metrics.
3.  **BCubed Precision and Recall:** o Precision and recall are measures of how well the clusters match the ground truth. K=2 has the highest BCubed recall, suggesting that it captures the ground truth better. However, precision is quite low, indicating that while it captures a lot of the true positives, it also has a high rate of false positives.

**Conclusion:** • Based on the provided metrics, K=2 seems to be a reasonable choice. It has the highest silhouette width and recall, although precision is relatively low so, the choice of the best cluster is highly dependent in specific goals and characteristics of the dataset.

# Findings

## Classification Findings

The results of the classification analysis, particularly when evaluating different models and data splits, provide valuable insights into the performance of the predictive model for employee salaries. Let's break down the key findings:

1.  **Accuracy:**
    -   Accuracy measures how well the model correctly predicts the salary categories. The observed accuracy ranging from 53.24% to 60.28% suggests that the model is reasonably effective in predicting employee salaries.
2.  **Model Comparison:**
    -   The gain ratio model consistently outperforms other models (Gini Index, Information Gain) in terms of accuracy and kappa values. This indicates that the gain ratio model is more reliable and aligns better with the actual salary categories.
3.  **Data Split Impact:**
    -   The evaluation results show that the 90% training and 10% testing split generally yields better performance in terms of sensitivity and specificity compared to the 70-30 and 80-20 splits. This suggests that a larger training set contributes to a more effective model.
4.  **Decision Tree Interpretation:**
    -   The decision tree provides a structured way to understand how the model makes predictions based on various features such as work year, experience level, job title, and company location. It offers transparency into the decision-making process.
5.  **Sensitivity and Specificity:**
    -   Sensitivity and specificity metrics provide insights into the model's ability to correctly identify positive and negative cases. The variations across different models and splits indicate how well the models perform in distinguishing between different salary categories.
6.  **Recommendations:**
    -   The recommendation to use the gain ratio model with a 90% training and 10% testing split is based on its superior performance in terms of accuracy and kappa. This combination is suggested for organizations looking to predict employee salaries effectively.
7.  **Implications:**
    -   The results have practical implications for organizations involved in workforce management and compensation planning. Accurate predictions of employee salaries can inform decisions related to hiring, retention, and overall human resources strategies.

In summary, the results signify the model's effectiveness in predicting employee salaries, with the gain ratio model and the 90-10 split identified as the preferred choices based on their superior performance. These findings contribute valuable insights for organizations seeking reliable and accurate salary predictions.

## Clustering Findings

Our exploration into clustering methods for our dataset has led us to a crucial revelation. It appears that the conventional clustering approach, particularly with k=10, may not be the optimal choice. The issue arises from undesirable overlapping clusters, contradicting the expectation of distinct, tightly grouped clusters around their centers.

**Key Findings:**

1.  **Ineffectiveness of k=10:** The utilization of k=10 results in clusters that are too close, with objects within each cluster distant from the center. This departure from standard clustering norms indicates the unsuitability of k=10 for our dataset.

2.  **Standout Option: k=2:** Despite lower precision and potential overlap, k=2 emerges as the best clustering option, displaying the highest Recall value. This suggests that k=2 effectively captures a comprehensive representation of items from the same category within their clusters.

3.  **Reasonable Alternative: k=3:** For those seeking a balance between precision and recall, k=3 presents itself as a reasonable choice for clustering.

**Summary and Implications:** In summary, the exploration strongly argues against using 10 clusters for our dataset due to the deviation from standard clustering criteria. Instead, it highlights the suitability of a classification method. Unlike clustering, classification seems more effective in categorizing our dataset. Therefore, we recommend considering a classification approach as a more appropriate and fruitful method for our dataset.

## problem solutions

In the ever-evolving field of data science, where salaries hold immense importance, we're introducing a user-friendly prediction tool. This tool, powered by the simplicity of classification, is designed to unravel the factors influencing data science salaries, offering individuals and businesses a clear understanding of market trends and promoting fair compensation practices.

Our streamlined approach involves creating a model with a straightforward 90-10 split, focusing on essential details like experience level, job type, years of service, salary, and more. What sets our solution apart is the use of the Gain Ratio algorithm, ensuring reliable and accurate predictions. We made a conscious decision to exclude clustering from our methodology, recognizing it as not the best fit for this scenario. This ensures that our model is honed for precision, delivering valuable insights for individuals making career decisions and aiding companies in establishing equitable compensation structures. With the 90-10 split and the strategic choice of the Gain Ratio algorithm, we are committed to simplifying the understanding of data science salaries for everyone involved.

## the final tree choosen  structure 
```{r}
library(C50)
library(partykit)
library(rpart.plot)
library(rpart)
library(rpart.plot)

model <- C5.0(salary_in_usd_disc ~., data=data_train)
party_model <- as.party(model)



# Plot the tree using default plotting method
plot(party_model,type="simple")



# Plot the tree with a simple text representation
print(party_model)
```
### Decision Tree Interpretation:

1. **Root Node:**
   - Decision based on company location.

2. **Node 2:**
   - Company location in Africa, Asia, Europe, Oceania predicts "low" salary.

3. **Node 3:**
   - For North America or Other, employment type and job title are crucial.

4. **Node 4:**
   - CT, FL, PT employment types predict "low" salary.

5. **Node 5:**
   - For FT employment, Data Analyst job title predicts "low" salary.

6. **Node 6:**
   - For Data Engineer, Data Scientist, or Other titles, experience level and remote ratio are key.

7. **Node 8:**
   - Experience level 2 predicts "mid" salary.

8. **Node 13:**
   - Experience level 4 predicts "high" salary.

9. **Node 15:**
   - For experience level 3 and specific remote ratios, predicts "high" salary.

### Important Features:

- **Company Location:** Influential in the initial salary prediction.
- **Job Title:** Significant, especially for Data Analyst and other roles.
- **Experience Level:** Critical, particularly for Data Engineer, Data Scientist, and other roles.
- **Remote Ratio:** Considered for specific job titles and experience levels.









# References


-   D. Singh, "Encoding Data with R \| Pluralsight," Nov. 12, 2019. [Online]. Available: <https://www.pluralsight.com/guides/encoding-data-with-r>

-   John, "How to Remove Outliers in R \| R-bloggers," R-bloggers, Jan. 19, 2020. [Online]. Available: <https://www.r-bloggers.com/2020/01/how-to-remove-outliers-in-r/>

-   "RPubs - Data Mining: Classification with Decision Trees." [Online]. Available: <https://rpubs.com/kjmazidi/195428>

-   D. Johnson, "Decision Tree in R: Classification Tree with Example," Guru99, Nov. 20, 2023. [Online]. Available: <https://www.guru99.com/r-decision-trees.html>

-   Zach, "How to Use the Elbow Method in R to Find Optimal Clusters," Statology, Sep. 08, 2022. [Online]. Available: <https://www.statology.org/elbow-method-in-r/>

-   "Clustering in R Programming," GeeksforGeeks, Jun. 08, 2023. [Online]. Available: <https://www.geeksforgeeks.org/clustering-in-r-programming/>

-   "Selecting the number of clusters with silhouette analysis on KMeans clustering," scikit-learn. <https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html>

-   J. Leskovec, A. Rajaraman, and J. D. Ullman, "Mining of Massive Datasets," Cambridge University Press, 2014.


